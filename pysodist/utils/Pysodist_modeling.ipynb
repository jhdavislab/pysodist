{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Steady-State Pulse-Labeling Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy as sc\n",
    "import scipy.optimize as opt\n",
    "import sympy as sp\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define functions to parse data, fit models, and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sub_pepscanfilt_csv(file_path):\n",
    "    parsed_timepoint_output = pd.read_csv(file_path, sep=',',usecols=['protein','pep','U/F','L/F','U/L'])\n",
    "    parsed_timepoint_output = parsed_timepoint_output.sort_values(by=['protein'])\n",
    "    return parsed_timepoint_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def protein_median(parsed_csv):\n",
    "    p_median_1 = parsed_csv.groupby(['protein'])\n",
    "    p_median_1 = p_median_1['L/F'].agg(np.median)\n",
    "    \n",
    "    p_median_2 = parsed_csv.groupby(['protein'])\n",
    "    p_median_2 = p_median_2['U/F'].agg(np.median)\n",
    "    \n",
    "    p_median_3 = parsed_csv.groupby(['protein'])\n",
    "    p_median_3 = p_median_3['Total'].agg(np.median)\n",
    "    \n",
    "    p_median_4 = parsed_csv.groupby(['protein'])\n",
    "    p_median_4 = p_median_4['Frac_labeled'].agg(np.median)\n",
    "    \n",
    "    unique_prots = parsed_csv['protein'].unique()\n",
    "    \n",
    "    column_names = ['protein','L/F','U/F', 'Total', 'Frac_labeled']\n",
    "    protein_median = pd.DataFrame(columns = column_names)\n",
    "    \n",
    "    index = []\n",
    "    for itr in range(len(unique_prots)):\n",
    "        new_row = {'protein':unique_prots[itr],'L/F':p_median_1[itr],'U/F':p_median_2[itr], 'Total':p_median_3[itr], 'Frac_labeled':p_median_4[itr]}\n",
    "        protein_median = protein_median.append(new_row, ignore_index = True)\n",
    "        index.append(itr)\n",
    "\n",
    "    protein_median.set_index(['protein'], inplace=True)\n",
    "        \n",
    "    return protein_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_timepoints(pmeds_lib, dil_times, dil_factors):\n",
    "    prot_meds_keys = list(pmeds_lib.keys())\n",
    "    prot_meds_keys.sort()\n",
    "    \n",
    "    joint_df = pmeds_lib[prot_meds_keys[0]].join(pmeds_lib[prot_meds_keys[1]], lsuffix = '_' + str(prot_meds_keys[0]), rsuffix = '_' + str(prot_meds_keys[1]), how = 'inner')\n",
    "    \n",
    "    if len(prot_meds_keys) > 2:\n",
    "        for i in range(2, len(prot_meds_keys)):\n",
    "            l = \"L/F\" + \"_\" + str(prot_meds_keys[i])\n",
    "            u = \"U/F\" + \"_\" + str(prot_meds_keys[i])\n",
    "            t = \"Total\" + \"_\" + str(prot_meds_keys[i])\n",
    "            f = \"Frac_labeled\" + \"_\" + str(prot_meds_keys[i])\n",
    "            \n",
    "            joint_df = joint_df.join(pmeds_lib[prot_meds_keys[i]], how = 'inner')\n",
    "            joint_df.rename(columns = {\"L/F\": l, \"U/F\": u, \"Total\": t, \"Frac_labeled\": f}, inplace = True)\n",
    " \n",
    "    return prot_meds_keys, joint_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pulse_fitting(dirname, OD_data, dil_times, dil_factors, global_k = True,  extension = '_pepscanfilt.csv'):\n",
    "    '''\n",
    "    PULSE_FITTING reads a series of .csv files output by pysodist to generate OD-corrected light/heavy and pulse/heavy ratios,\n",
    "    finds the (pulse/heavy)(pulse/heavy + light/heavy) fractions across the time series, and fits to models 0, 1, and 3 with fixed\n",
    "    k determined from the OD data, adjusted by the dilution factors used during the course of the experiment\n",
    "    '''\n",
    "    \n",
    "    #updating matplotlib parameters\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    plt.rcParams.update({'axes.linewidth': 1.0})\n",
    "    \n",
    "    #read in data\n",
    "    parsed_data = {}\n",
    "    for i in os.listdir(dirname):\n",
    "        if i.endswith(extension):\n",
    "            key = int(i.split('_')[0])\n",
    "            parsed_data[key] = parse_sub_pepscanfilt_csv(dirname + i)\n",
    "\n",
    "            for j in range(0, len(dil_times)):\n",
    "                if key > dil_times[j]:\n",
    "                    parsed_data[key]['U/F'] = parsed_data[key]['U/F']*dil_factors[j]\n",
    "                    parsed_data[key]['L/F'] = parsed_data[key]['L/F']*dil_factors[j]\n",
    "\n",
    "            parsed_data[key]['Total'] = parsed_data[key]['U/F'] + parsed_data[key]['L/F']\n",
    "            parsed_data[key]['Frac_labeled'] = parsed_data[key]['L/F']/(parsed_data[key]['U/F'] + parsed_data[key]['L/F'])\n",
    "\n",
    "    #calculate median by protein\n",
    "    prot_meds = {}\n",
    "    for i in parsed_data.keys():\n",
    "        prot_meds[i] = protein_median(parsed_data[i])\n",
    "    \n",
    "    #compare timepoints\n",
    "    time, time_df = compare_timepoints(prot_meds, dil_times, dil_factors)\n",
    "    \n",
    "    #create dfs with total U+L and fraction labeled L/U+L\n",
    "    totals = time_df[time_df.columns[time_df.columns.str.contains('Total')]]\n",
    "    fracs = time_df[time_df.columns[time_df.columns.str.contains('Frac_labeled')]]\n",
    "    \n",
    "    fig1, ax1 = plt.subplots(1, 2)\n",
    "    fig1.set_size_inches(20, 5)\n",
    "    for i in np.arange(0, len(fracs.index), 1):\n",
    "        ax1[0].plot(time, fracs.iloc[i, :])\n",
    "        ax1[0].set_ylim(0, 1)\n",
    "        ax1[0].set_xlabel('Time (min)')\n",
    "        ax1[0].set_ylabel('Labeled/(labeled + unlabeled)')\n",
    "        \n",
    "        ax1[1].plot(time, totals.iloc[i, :])\n",
    "        ax1[1].set_xlabel('Time (min)')\n",
    "        ax1[1].set_ylabel('Labeled + unlabeled')\n",
    "    \n",
    "    fig1.savefig(dirname + 'totals_fracs.png')\n",
    "    \n",
    "    #adjusting OD data\n",
    "    for i in range(0, len(dil_times)):\n",
    "        for j in range(0, len(time)):\n",
    "            if time[j] > dil_times[i]:\n",
    "                OD_data[j] = OD_data[j]*dil_factors[i]\n",
    "    \n",
    "    #fitting OD data to get global k value\n",
    "    def single_exp(t, a, k_app, c):\n",
    "        return a * np.exp(k_app * t) + c\n",
    "    param_guess = [1, 10**-4, 0]\n",
    "    OD_fit = opt.curve_fit(single_exp, time, OD_data, p0 = param_guess)[0]\n",
    "        \n",
    "    assert type(global_k) == bool\n",
    "    \n",
    "    k = OD_fit[1]\n",
    "    k_list = []\n",
    "    \n",
    "    if global_k == False:\n",
    "        for prot in totals.index:\n",
    "            totals_data = np.array([totals.at[prot, i] for i in totals.columns])\n",
    "            totals_fit = opt.curve_fit(single_exp, time, totals_data, p0 = param_guess)[0]\n",
    "            k_list.append(totals_fit[1])\n",
    "    \n",
    "    #plotting OD fit\n",
    "    fig2, ax2 = plt.subplots(1, 1)\n",
    "    ax2.plot(time, OD_data, 'xk')\n",
    "    max_time = np.max(time)\n",
    "    pred_t = np.linspace(0, max_time, max_time*1000)\n",
    "    pred_y = single_exp(pred_t, *OD_fit)\n",
    "    ax2.plot(pred_t, pred_y, '-r')\n",
    "    ax2.set_xlabel('Time (min)')\n",
    "    ax2.set_ylabel('Adjusted OD600')\n",
    "    fig2.savefig(dirname + 'OD_fit.png')\n",
    "    \n",
    "    #defining functions for each model based on whether or not k is global\n",
    "    if global_k == True:\n",
    "        def model0(t, P):   \n",
    "            return 1.0 + P*np.exp(-k*(1.0 + 1.0/P)*t) - (1.0 + P)*np.exp(-k*t)\n",
    "        \n",
    "        def model1(t, P1, P2):\n",
    "            return 1.0 - k*(1.0 + P2)/(P2 - P1 - P1*P2)*np.exp(-k*(1.0 + P1 + P1*P2)*t) + (k*(1.0 + P2)/(P2 - P1 - P1*P2) - 1.0)*np.exp(-k*(1.0 + P2)*t)\n",
    "\n",
    "        def model3(t, P, beta):\n",
    "            return ((k + P*(k + beta))/(P*(k + beta) - k))*(1.0 - (k + beta)/(k*(2.0 - P) + beta*(1.0 - P))*np.exp(-1.0*(P*(k + beta) - k)*t) + (P*(k + beta) - k)/(k*(2.0 - P) + beta*(1.0 - P))*np.exp(-1.0*(k + beta)*t))\n",
    "    \n",
    "        \n",
    "        def model0_global(combined_x_data, P):\n",
    "\n",
    "            results = np.array([])\n",
    "\n",
    "            for i in np.arange(0, len(fracs.index), 1):\n",
    "                extracted_data = combined_x_data[len(time)*i:len(time)*(i + 1)]\n",
    "                results = np.append(results, model0(extracted_data, P))\n",
    "\n",
    "            return results\n",
    "\n",
    "        \n",
    "        def model1_global(combined_x_data, P1, P2):\n",
    "\n",
    "            results = np.array([])\n",
    "\n",
    "            for i in np.arange(0, len(fracs.index), 1):\n",
    "                extracted_data = combined_x_data[len(time)*i:len(time)*(i + 1)]\n",
    "                results = np.append(results, model1(extracted_data, P1, P2))\n",
    "\n",
    "            return results\n",
    "\n",
    "        \n",
    "        def model3_global(combined_x_data, P, *betas):\n",
    "            results = np.array([])\n",
    "\n",
    "            betas = np.array([beta for beta in betas])\n",
    "            for i in np.arange(0, len(betas)):\n",
    "                extracted_data = combined_x_data[len(time)*i:len(time)*(i +1)]\n",
    "                results = np.append(results, model3(extracted_data, P, betas[i]))\n",
    "\n",
    "            return results\n",
    "        \n",
    "    elif global_k == False:\n",
    "        \n",
    "\n",
    "        def model0_global(combined_x_data, P):\n",
    "\n",
    "            results = np.array([])\n",
    "\n",
    "            for i in np.arange(0, len(fracs.index), 1):\n",
    "                extracted_data = combined_x_data[len(time)*i:len(time)*(i + 1)]\n",
    "                k = k_list[i]\n",
    "                def model0(t, P):   \n",
    "                    return 1.0 + P*np.exp(-k*(1.0 + 1.0/P)*t) - (1.0 + P)*np.exp(-k*t)\n",
    "                results = np.append(results, model0(extracted_data, P))\n",
    "\n",
    "            return results\n",
    "\n",
    "        \n",
    "        def model1_global(combined_x_data, P1, P2):\n",
    "\n",
    "            results = np.array([])\n",
    "\n",
    "            for i in np.arange(0, len(fracs.index), 1):\n",
    "                extracted_data = combined_x_data[len(time)*i:len(time)*(i + 1)]\n",
    "                k = k_list[i]\n",
    "                def model1(t, P1, P2):\n",
    "                    return 1.0 - k*(1.0 + P2)/(P2 - P1 - P1*P2)*np.exp(-k*(1.0 + P1 + P1*P2)*t) + (k*(1.0 + P2)/(P2 - P1 - P1*P2) - 1.0)*np.exp(-k*(1.0 + P2)*t)\n",
    "                results = np.append(results, model1(extracted_data, P1, P2))\n",
    "\n",
    "            return results\n",
    "        \n",
    "        def model3_global(combined_x_data, P, *betas):\n",
    "\n",
    "            results = np.array([])\n",
    "\n",
    "            betas = np.array([beta for beta in betas])\n",
    "\n",
    "            for i in np.arange(0, len(betas)):\n",
    "                extracted_data = combined_x_data[len(time)*i:len(time)*(i +1)]\n",
    "                k = k_list[i]\n",
    "                def model3(t, P, beta):\n",
    "                    return ((k + P*(k + beta))/(P*(k + beta) - k))*(1.0 - (k + beta)/(k*(2.0 - P) + beta*(1.0 - P))*np.exp(-1.0*(P*(k + beta) - k)*t) + (P*(k + beta) - k)/(k*(2.0 - P) + beta*(1.0 - P))*np.exp(-1.0*(k + beta)*t))\n",
    "\n",
    "                results = np.append(results, model3(extracted_data, P, betas[i]))\n",
    "\n",
    "            return results\n",
    "        \n",
    "                \n",
    "    def calc_resids(function, x_vals, y_vals, *function_params):   \n",
    "        resids = [(y_vals[i] - function(x_vals[i], *function_params)) for i in range(0, len(y_vals))] \n",
    "        sq_resids = [resids[i]**2 for i in range (0, len(resids))] \n",
    "        sum_sq_resids = sum(sq_resids)\n",
    "        return resids, sum_sq_resids\n",
    "                \n",
    "    def calc_resids_global(function, x_vals, y_vals, *function_params): \n",
    "        func_data = function(x_vals, *function_params)\n",
    "        resids = [(y_vals[i] - func_data[i]) for i in range(0, len(y_vals))]\n",
    "        sq_resids = [resids[i]**2 for i in range (0, len(resids))] \n",
    "        sum_sq_resids = sum(sq_resids)\n",
    "        return resids, sum_sq_resids\n",
    "    \n",
    "    fit_results = pd.DataFrame(index = ['model0', 'model1', 'model3'], columns = ['Parameters', 'SSR'])\n",
    "    \n",
    "    function_set = [model0_global, model1_global, model3_global]\n",
    "    \n",
    "    #updating matplotlib parameter for plotting\n",
    "    plt.rcParams.update({'font.size': 24})\n",
    "    plt.rcParams.update({'axes.linewidth': 3.0})\n",
    "    \n",
    "    #running the actual fitting with each of the three models\n",
    "    for function in function_set:\n",
    "        nrows = int(np.ceil(len(fracs)/3))\n",
    "        fig3, ax3 = plt.subplots(nrows, 3)    \n",
    "        ax3 = ax3.flatten()\n",
    "        fig3.set_size_inches(40, 300)\n",
    "        style = np.array(['.k', '--r'])\n",
    "        fig4, ax4 = plt.subplots(1, 1)\n",
    "        \n",
    "        if function == model0_global:\n",
    "            param_guess = 1000\n",
    "            lb = 0\n",
    "            ub = np.inf\n",
    "            paramets = ['P']\n",
    "            if global_k == True:\n",
    "                local_function = model0\n",
    "        elif function == model1_global:\n",
    "            param_guess = [1000, 1]\n",
    "            lb = [0, 0]\n",
    "            ub = [np.inf, np.inf]\n",
    "            paramets = ['P1', 'P2']\n",
    "            if global_k == True:\n",
    "                local_function = model1\n",
    "        elif function == model3_global:\n",
    "            beta_guess = np.zeros(len(fracs.index))\n",
    "            beta_ub = 10**10*np.ones(len(fracs.index))\n",
    "            beta_lb = np.zeros(len(fracs.index))\n",
    "            param_guess = np.append([1000], beta_guess)\n",
    "            lb = np.append([0], beta_lb)\n",
    "            ub = np.append(np.inf, beta_ub)\n",
    "            paramets = ['P', 'Beta']\n",
    "            if global_k == True:\n",
    "                local_function = model3\n",
    "        \n",
    "        #generating the global x and y data arrays\n",
    "        x_data = np.tile(time, len(fracs.index)) \n",
    "        y_data = np.array([])\n",
    "        for protein in fracs.index:\n",
    "            \n",
    "            y_data = np.append(y_data, fracs.loc[protein, :])        \n",
    "            y_data = np.array(y_data, dtype = np.float64)\n",
    "        \n",
    "        #try running the fit, except if there's a RunTime error (unable to fit)\n",
    "        try:\n",
    "            fit_results_i = opt.curve_fit(function, x_data, y_data, p0 = param_guess, bounds = (lb, ub))[0]\n",
    "            SSR = calc_resids_global(function, x_data, y_data, *fit_results_i)[1]\n",
    "\n",
    "            preds_t = np.linspace(0, max(time), num = max(time)*100) \n",
    "        \n",
    "            for i in range(len(fracs.index)):\n",
    "                ax3[i].scatter(x_data[i*len(fracs.columns):(i + 1)*len(fracs.columns)], y_data[i*len(fracs.columns):(i + 1)*len(fracs.columns)], s = 40.0, c = 'k')\n",
    "\n",
    "                if function == model0_global or function == model1_global:\n",
    "                    local_params = fit_results_i\n",
    "                elif function ==  model3_global:\n",
    "                    local_params = fit_results_i[[0, i + 1]]\n",
    "                \n",
    "                if global_k == False:\n",
    "                    k = k_list[i]\n",
    "                    if function == model0_global:\n",
    "                        def model0(t, P):   \n",
    "                            return 1.0 + P*np.exp(-k*(1.0 + 1.0/P)*t) - (1.0 + P)*np.exp(-k*t)\n",
    "                        local_function = model0\n",
    "                    if function == model1_global:\n",
    "                        def model1(t, P1, P2):\n",
    "                            return 1.0 - k*(1.0 + P2)/(P2 - P1 - P1*P2)*np.exp(-k*(1.0 + P1 + P1*P2)*t) + (k*(1.0 + P2)/(P2 - P1 - P1*P2) - 1.0)*np.exp(-k*(1.0 + P2)*t)\n",
    "                        local_function = model1\n",
    "                    if function == model3_global:\n",
    "                        def model3(t, P, beta):\n",
    "                            return ((k + P*(k + beta))/(P*(k + beta) - k))*(1.0 - (k + beta)/(k*(2.0 - P) + beta*(1.0 - P))*np.exp(-1.0*(P*(k + beta) - k)*t) + (P*(k + beta) - k)/(k*(2.0 - P) + beta*(1.0 - P))*np.exp(-1.0*(k + beta)*t))\n",
    "                        local_function = model3\n",
    "                \n",
    "                #plot real data vs predicted values from fit\n",
    "                preds_y = local_function(preds_t, *local_params)\n",
    "                \n",
    "                ax3[i].plot(preds_t, preds_y, '--r', linewidth = 6.0)\n",
    "\n",
    "                ax3[i].set_ylim([0, 1])\n",
    "                ax3[i].set_xlabel('Time (min)')\n",
    "                protein_name = fracs.index[i].split('_')[0]\n",
    "                ax3[i].set_ylabel(', '.join([protein_name, 'L/(U+L)']))\n",
    "\n",
    "\n",
    "            #clean up the figure\n",
    "            if np.mod(i + 1, 3) == 1:\n",
    "                fig3.delaxes(ax3[i + 1])\n",
    "                fig3.delaxes(ax3[i + 2])\n",
    "            elif np.mod(i + 1, 3) == 2:\n",
    "                fig3.delaxes(ax3[i + 1])\n",
    "            \n",
    "            #save the figures\n",
    "            if global_k == True:\n",
    "                fig3.savefig(dirname + '_'.join([str(function).split('>.')[1].split(' ')[0], 'fits.png']))\n",
    "                fig4.savefig(dirname + '_'.join([str(function).split('>.')[1].split(' ')[0], 'resids.png']))\n",
    "            elif global_k == False:\n",
    "                fig3.savefig(dirname + '_'.join([str(function).split('>.')[1].split(' ')[0], 'fits_non-global-k.png']))\n",
    "                fig4.savefig(dirname + '_'.join([str(function).split('>.')[1].split(' ')[0], 'resids_non-global-k.png']))\n",
    "                \n",
    "        except RuntimeError:\n",
    "            fit_results_i = np.nan\n",
    "        \n",
    "        #store the results of the fit in a df\n",
    "        model_name = str(function).split('>.')[1].split(' ')[0].split('_')[0]\n",
    "        fit_results.loc[model_name, 'Parameters'] = fit_results_i\n",
    "        fit_results.loc[model_name, 'SSR'] = SSR\n",
    "                \n",
    "        \n",
    "    if global_k == True:\n",
    "        return k, fracs, totals, fit_results\n",
    "    else:\n",
    "        return k_list, fracs, totals, fit_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parsing and fitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: './allpepscanfilt/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-eb5ef47d3bc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mods\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mk_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfracs_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotals_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfits_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpulse_fitting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./allpepscanfilt/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mods\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m360\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m480\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-abe6700e0d48>\u001b[0m in \u001b[0;36mpulse_fitting\u001b[1;34m(dirname, OD_data, dil_times, dil_factors, global_k, extension)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#read in data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mparsed_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextension\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: './allpepscanfilt/'"
     ]
    }
   ],
   "source": [
    "ods = [0.5, 0.6, 0.7, 0.8, 0.9, 1.1, 1.4, 1.5, 1.8, 2.1, 2.3, 2.4, 3.0, 1.9, 2.3, 2.6, 3.0, 1.8, 2.1, 2.4]\n",
    "k_fit, fracs_df, totals_df, fits_df = pulse_fitting('./allpepscanfilt/', ods, [360, 480], [2, 2], global_k = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005340380483213396"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pysodist run_isodist ./Gal_15N_0_DIA/pd_exported_peaks.tsv /nobackup/users/lkinman/software/pysodist/fortran/isodist ./model_files/atoms.txt ./model_files/U_fix500N_998N_t0.txt --threads 160 --pysodist_input ./Gal_15N_0_DIA/pd_parsed_report.tsv\n",
      "pysodist run_isodist ./Gal_15N_30_DIA/pd_exported_peaks.tsv /nobackup/users/lkinman/software/pysodist/fortran/isodist ./model_files/atoms.txt ./model_files/U_fix401N_998N_t30.txt --threads 160 --pysodist_input ./Gal_15N_30_DIA/pd_parsed_report.tsv\n",
      "pysodist run_isodist ./Gal_15N_60_DIA/pd_exported_peaks.tsv /nobackup/users/lkinman/software/pysodist/fortran/isodist ./model_files/atoms.txt ./model_files/U_fix372N_998N_t60.txt --threads 160 --pysodist_input ./Gal_15N_60_DIA/pd_parsed_report.tsv\n",
      "pysodist run_isodist ./Gal_15N_90_DIA/pd_exported_peaks.tsv /nobackup/users/lkinman/software/pysodist/fortran/isodist ./model_files/atoms.txt ./model_files/U_fix390N_998N_t90.txt --threads 160 --pysodist_input ./Gal_15N_90_DIA/pd_parsed_report.tsv\n",
      "pysodist run_isodist ./Gal_15N_120_DIA/pd_exported_peaks.tsv /nobackup/users/lkinman/software/pysodist/fortran/isodist ./model_files/atoms.txt ./model_files/U_fix403N_998N_t120.txt --threads 160 --pysodist_input ./Gal_15N_120_DIA/pd_parsed_report.tsv\n",
      "pysodist run_isodist ./Gal_15N_150_DIA/pd_exported_peaks.tsv /nobackup/users/lkinman/software/pysodist/fortran/isodist ./model_files/atoms.txt ./model_files/U_fix418N_998N_t150.txt --threads 160 --pysodist_input ./Gal_15N_150_DIA/pd_parsed_report.tsv\n",
      "pysodist run_isodist ./Gal_15N_180_DIA/pd_exported_peaks.tsv /nobackup/users/lkinman/software/pysodist/fortran/isodist ./model_files/atoms.txt ./model_files/U_fix421N_998N_t180.txt --threads 160 --pysodist_input ./Gal_15N_180_DIA/pd_parsed_report.tsv\n",
      "pysodist run_isodist ./Gal_15N_210_DIA/pd_exported_peaks.tsv /nobackup/users/lkinman/software/pysodist/fortran/isodist ./model_files/atoms.txt ./model_files/U_fix429N_998N_t210.txt --threads 160 --pysodist_input ./Gal_15N_210_DIA/pd_parsed_report.tsv\n",
      "pysodist run_isodist ./Gal_15N_240_DIA/pd_exported_peaks.tsv /nobackup/users/lkinman/software/pysodist/fortran/isodist ./model_files/atoms.txt ./model_files/U_fix433N_998N_t240.txt --threads 160 --pysodist_input ./Gal_15N_240_DIA/pd_parsed_report.tsv\n",
      "pysodist run_isodist ./Gal_15N_270_DIA/pd_exported_peaks.tsv /nobackup/users/lkinman/software/pysodist/fortran/isodist ./model_files/atoms.txt ./model_files/U_fix437N_998N_t270.txt --threads 160 --pysodist_input ./Gal_15N_270_DIA/pd_parsed_report.tsv\n",
      "pysodist run_isodist ./Gal_15N_300_DIA/pd_exported_peaks.tsv /nobackup/users/lkinman/software/pysodist/fortran/isodist ./model_files/atoms.txt ./model_files/U_fix439N_998N_t300.txt --threads 160 --pysodist_input ./Gal_15N_300_DIA/pd_parsed_report.tsv\n",
      "pysodist run_isodist ./Gal_15N_330_DIA/pd_exported_peaks.tsv /nobackup/users/lkinman/software/pysodist/fortran/isodist ./model_files/atoms.txt ./model_files/U_fix442N_998N_t330.txt --threads 160 --pysodist_input ./Gal_15N_330_DIA/pd_parsed_report.tsv\n",
      "pysodist run_isodist ./Gal_15N_360_DIA/pd_exported_peaks.tsv /nobackup/users/lkinman/software/pysodist/fortran/isodist ./model_files/atoms.txt ./model_files/U_fix443N_998N_t360.txt --threads 160 --pysodist_input ./Gal_15N_360_DIA/pd_parsed_report.tsv\n",
      "pysodist run_isodist ./Gal_15N_390_DIA/pd_exported_peaks.tsv /nobackup/users/lkinman/software/pysodist/fortran/isodist ./model_files/atoms.txt ./model_files/U_fix447N_998N_t390.txt --threads 160 --pysodist_input ./Gal_15N_390_DIA/pd_parsed_report.tsv\n",
      "pysodist run_isodist ./Gal_15N_420_DIA/pd_exported_peaks.tsv /nobackup/users/lkinman/software/pysodist/fortran/isodist ./model_files/atoms.txt ./model_files/U_fix448N_998N_t420.txt --threads 160 --pysodist_input ./Gal_15N_420_DIA/pd_parsed_report.tsv\n",
      "pysodist run_isodist ./Gal_15N_450_DIA/pd_exported_peaks.tsv /nobackup/users/lkinman/software/pysodist/fortran/isodist ./model_files/atoms.txt ./model_files/U_fix449N_998N_t450.txt --threads 160 --pysodist_input ./Gal_15N_450_DIA/pd_parsed_report.tsv\n",
      "pysodist run_isodist ./Gal_15N_480_DIA/pd_exported_peaks.tsv /nobackup/users/lkinman/software/pysodist/fortran/isodist ./model_files/atoms.txt ./model_files/U_fix451N_998N_t480.txt --threads 160 --pysodist_input ./Gal_15N_480_DIA/pd_parsed_report.tsv\n",
      "pysodist run_isodist ./Gal_15N_510_DIA/pd_exported_peaks.tsv /nobackup/users/lkinman/software/pysodist/fortran/isodist ./model_files/atoms.txt ./model_files/U_fix453N_998N_t510.txt --threads 160 --pysodist_input ./Gal_15N_510_DIA/pd_parsed_report.tsv\n",
      "pysodist run_isodist ./Gal_15N_540_DIA/pd_exported_peaks.tsv /nobackup/users/lkinman/software/pysodist/fortran/isodist ./model_files/atoms.txt ./model_files/U_fix454N_998N_t540.txt --threads 160 --pysodist_input ./Gal_15N_540_DIA/pd_parsed_report.tsv\n",
      "pysodist run_isodist ./Gal_15N_570_DIA/pd_exported_peaks.tsv /nobackup/users/lkinman/software/pysodist/fortran/isodist ./model_files/atoms.txt ./model_files/U_fix457N_998N_t570.txt --threads 160 --pysodist_input ./Gal_15N_570_DIA/pd_parsed_report.tsv\n"
     ]
    }
   ],
   "source": [
    "frcs = [0.500, 0.401, 0.372, 0.39, 0.403, 0.418, 0.421, 0.429, 0.433, 0.437, 0.439, 0.442, 0.443, 0.447, 0.448, 0.449, 0.451, 0.453, 0.454, 0.457]\n",
    "\n",
    "j = 0\n",
    "for i in range(0, 600, 30):\n",
    "    print('pysodist run_isodist ./Gal_15N_' + str(i) + '_DIA/pd_exported_peaks.tsv /nobackup/users/lkinman/software/pysodist/fortran/isodist ./model_files/atoms.txt ./model_files/U_fix' + '{:.3f}'.format(frcs[j]).split('.')[1] + 'N_998N_t' + str(i) + '.txt --threads 160 --pysodist_input ./Gal_15N_' + str(i) + '_DIA/pd_parsed_report.tsv')\n",
    "    j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.500'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
